{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Selekcja cech\n",
    "## Usuwanie cech o niskiej wariancji\n",
    "---\n",
    "Usuwamy wszystkie cechy, których wariancja jest poniżej pewnego progu (domyślnie usuwane są cechy o wariancji równej 0).  \n",
    "Dla zmiennych binarnych wariancja wyrażona jest wzorem: <b><i>Var[X] = p(p-1)</i></b>  \n",
    "Przykład dla progu 0.8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(0.8 * (1 - 0.8)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać usunięta została pierwsza cecha. Prawdopodobieństwo wystąpienia zera <b><i>p = 5/6</i></b> > 0.8  \n",
    "\n",
    "## Sequential feature selection\n",
    "---\n",
    "### <span id=\"filterapproach\">Filter approach</span>\n",
    "W tym podejściu dla każdej cechy wyliczana jest odpowiednia wartość testu statystycznego, podanego jako parametr <code>score_func</code>, a następnie wybierane jest <i>k</i> cech, które uzyskały najwyższe wartości.  \n",
    "Dostępne funkcje testujące:  \n",
    "Dla regresji: <code>f_regression</code>, <code>mutual_info_regression</code>  \n",
    "Dla klasyfikacji: <code>chi2</code>, <code>f_classif</code>, <code>mutual_info_classif</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako przykład wykorzystamy dane ze zbioru UCI: <a href=\"https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\"><b>Breast Cancer Wisconsin (Diagnostic) Data Set</b></a>, dotyczące klasyfikacji raka piersi jako złośliwego bądź łagodnego, na podstawie pomiarów jąder komórkowych uzyskanych ze zdjęć pobranej masy.  \n",
    "\n",
    "Dla każdego przypadku oprócz identyfikatora pacjenta oraz diagnozy podane są zmierzone wartości dotyczące jąder komórkowych. Mierzonych cech jest 10, natomiast dla każdej z nich podana jest najpierw wartość średnia, następnie wartość błędu standardowego, a na koniec najgorsza ze zmierzonych wartości, co daje w sumie 30 cech.  \n",
    "\n",
    "Wszystkich przypadków jest 569\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytanie danych\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_cancer = pd.read_csv(\"data/wdbc.data\")\n",
    "\n",
    "# podgląd z jakimi danymi mamy do czynienia\n",
    "\n",
    "df_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podział na cechy i klasyfikację\n",
    "\n",
    "df_cancer_x = df_cancer.iloc[:,2:]\n",
    "df_cancer_y = df_cancer.iloc[:,1]\n",
    "data_cancer_x = df_cancer_x.to_numpy()\n",
    "data_cancer_y = df_cancer_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizacja danych\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler_cancer = preprocessing.Normalizer().fit(data_cancer_x)\n",
    "data_cancer_x_scaled = scaler_cancer.transform(data_cancer_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym przypadku zastosujemy test <b><i>chi<sup>2</sup></i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.bulldogjob.com/system/photos/files/000/005/477/original/grafika5.png\" width=\"70%\"/>  \n",
    "\n",
    "Wybieramy <b>10</b> najlepszych cech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bestfeatures_cancer = SelectKBest(score_func=chi2, k=10)\n",
    "fit_cancer = bestfeatures_cancer.fit(data_cancer_x_scaled, data_cancer_y)\n",
    "\n",
    "# wyświetlenie uporządkowanego histogramu istotności cech\n",
    "\n",
    "feat_importances_cancer = pd.Series(fit_cancer.scores_, index=df_cancer_x.columns)\n",
    "feat_importances_cancer.nlargest(10).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "# zapisanie listy najlepszych cech\n",
    "\n",
    "best_cancer_features = feat_importances_cancer.nlargest(10).index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper approach\n",
    "W tym podejściu iteracyjnie dobieramy cechy w oparciu o wydajność klasyfikatora. Zaczynamy z pustym zbiorem cech, w każdej iteracji dodajemy jedną cechę - jeśli dodanie jej zwiększyło wydajność klasyfikatora, to zostaje ona już w naszym podzbiorze. Proces ten powtarzamy do momentu, aż osiągniemy wymaganą liczbę cech. Podejście to jest bardziej kosztowne od <a href=\"#filterapproach\">Filter approach</a>, ponieważ za każdym razem musimy wytrenować model i ocenić jego wydajność. Zdarzają się również przypadki, że dodanie kilku nieco gorszych cech dałoby znacznie lepszy rezultat końcowy niż dodanie jednej najlepszej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selekcja cech z modelu za pomocą Feature Importances\n",
    "---\n",
    "Klasyfikatory oparte na drzewach decyzyjnych posiadają atrybut <code>feature_importances_</code>, który opisuje istotność cech wytrenowanego modelu.  \n",
    "W tym przykładzie wykorzystamy ponownie dane z UCI: <a href=\"https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\"><b>Breast Cancer Wisconsin (Diagnostic) Data Set</b></a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystamy klasyfikator <code>ExtraTreesClassifier</code>, <a href=\"https://pl.wikipedia.org/wiki/Drzewo_decyzyjne#Drzewa_decyzyjne_w_uczeniu_maszynowym\">przystępny opis na Wikipedii</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# wytrenowanie modelu\n",
    "\n",
    "model_cancer = ExtraTreesClassifier()\n",
    "model_cancer.fit(data_cancer_x_scaled, data_cancer_y)\n",
    "\n",
    "# selekcja najistotniejszych cech\n",
    "\n",
    "feat_importances_cancer = pd.Series(model_cancer.feature_importances_, index=df_cancer_x.columns)\n",
    "feat_importances_cancer.nlargest(10).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "# zapisanie listy najlepszych cech\n",
    "\n",
    "best_cancer_features2 = feat_importances_cancer.nlargest(10).index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse feature selection\n",
    "---\n",
    "### <span id=\"rfe\">Rekurencyjna eliminacja cech</span>\n",
    "W tej metodzie możemy użyć dowolnego estymatora posiadającego atrybut <code>feature_importances_</code>. Celem rekurencyjnej eliminacji cech (RFE) jest selekcja przez rekurencyjne uwzględnienie coraz mniejszych zestawów cech. Najpierw estymator jest szkolony na początkowym zestawie cech, znaczenie każdej z nich uzyskiwane jest przez atrybut <code>feature_importances_</code>. Najmniej znaczące cechy są usuwane z zestawu. Powtarza się to rekurencyjnie, aż pozostanie wymagana liczba cech.  \n",
    "W tym przykładzie wybierzemy 5 najlepszych cech (dla danych : <a href=\"https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\"><b>Breast Cancer Wisconsin (Diagnostic) Data Set</b></a>), odrzucając w każdym kroku 5 najgorszych cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe_selector = RFE(estimator=ExtraTreesClassifier(), n_features_to_select=5, step=5, verbose=5)\n",
    "rfe_selector.fit(data_cancer_x_scaled, data_cancer_y)\n",
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = df_cancer_x.loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')\n",
    "print(rfe_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie\n",
    "---\n",
    "Wykorzystać dane z UCI, tym razem dotyczące przewidywania rozwodów na podstawie oceny zachowań pomiędzy partnerami w skali od 0 do 4, dataset: <a href=\"https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set\"><b>Divorce Predictors data set Data Set</b></a>  \n",
    "<b>Pod podanym linkiem opisane jest znaczenie poszczególnych cech.</b>  \n",
    "Zbadano 170 przypadków, każdemu mężczyźnie zadano 54 pytania dotyczące jego małżeństwa/żony.  \n",
    "Class 1 oznacza szczęśliwe małżeństwo, 0 oznacza, że doszło do rozwodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytanie danych\n",
    "\n",
    "df_divorce = pd.read_csv(\"data/divorce.csv\", sep=';')\n",
    "\n",
    "# podgląd z jakimi danymi mamy do czynienia\n",
    "\n",
    "df_divorce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podział na cechy i klasyfikację\n",
    "df_divorce_x = df_divorce.iloc[:,:54]\n",
    "df_divorce_y = df_divorce.iloc[:,54]\n",
    "\n",
    "data_divorce_x = df_divorce_x.to_numpy()\n",
    "data_divorce_y = df_divorce_y.to_numpy()\n",
    "\n",
    "# normalizacja danych\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler_divorce = preprocessing.Normalizer().fit(data_divorce_x)\n",
    "data_divorce_x_scaled = scaler_divorce.transform(data_divorce_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Należy dla tych danych dokonać selekcji najlepszych cech przy pomocy <a href=\"#filterapproach\">Filter approach</a> wykorzystując test <b><i>chi<sup>2</sup></i></b> oraz wykorzystując <a href=\"#rfe\">RFE</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Badanie jakości klasyfikatorów k-nn\n",
    "---\n",
    "Dokonamy pomiaru jakości klasyfikatorów dla pełnego zestawu N cech, dla mniejszego zestawu m cech wybranych w sposób losowy i dla wyselekcjonowanego zestawu m najlepszych cech. Wykorzystamy do tego celu cechy wybrane za pomocą <a href=\"#filterapproach\">Filter approach</a>, które zapisaliśmy wcześniej jako <code>best_cancer_features</code>.  \n",
    "k = 1, 3, 5 (sąsiadów),  \n",
    "m = N, 5, 2 (cech)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_cancer_5 = best_cancer_features[:5]\n",
    "best_cancer_2 = best_cancer_features[:2]\n",
    "best_cancer = {\n",
    "    2: best_cancer_2,\n",
    "    5: best_cancer_5\n",
    "}\n",
    "\n",
    "import random\n",
    "random_cancer_5 = np.array(random.sample(list(df_cancer_x.columns), 5))\n",
    "random_cancer_2 = np.array(random.sample(list(df_cancer_x.columns), 2))\n",
    "random_cancer = {\n",
    "    2: random_cancer_2,\n",
    "    5: random_cancer_5\n",
    "}\n",
    "\n",
    "# pomiar dla N (wszystkich) cech\n",
    "for k_neigh in [1, 3, 5]:\n",
    "    loc_x_train, loc_x_test, loc_y_train, loc_y_test =  train_test_split(df_cancer_x,df_cancer_y, test_size=0.4, random_state=0 )\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k_neigh, algorithm='auto').fit(loc_x_train, loc_y_train)\n",
    "    y_pred = neigh.predict(loc_x_test)\n",
    "    score = accuracy_score(y_true = loc_y_test, y_pred = y_pred)\n",
    "    print('all \\tm = N, k = %d, score = %f' % (k_neigh, score))\n",
    "    \n",
    "    \n",
    "# pomiar m = 2, 5 cech (najlepszych oraz losowych)\n",
    "for m in [2, 5]:\n",
    "    loc_x_best_train, loc_x_best_test, loc_y_best_train, loc_y_best_test =  train_test_split(df_cancer_x.loc[:,best_cancer[m]],df_cancer_y, test_size=0.4, random_state=0 )\n",
    "    loc_x_random_train, loc_x_random_test, loc_y_random_train, loc_y_random_test =  train_test_split(df_cancer_x.loc[:,random_cancer[m]],df_cancer_y, test_size=0.4, random_state=0 )\n",
    "    for k_neigh in [1, 3, 5]:\n",
    "        # najlepsze cechy\n",
    "        neigh = KNeighborsClassifier(n_neighbors=k_neigh, algorithm='auto').fit(loc_x_best_train, loc_y_best_train)\n",
    "        y_best_pred = neigh.predict(loc_x_best_test)\n",
    "        best_score = accuracy_score(y_true = loc_y_best_test, y_pred = y_best_pred)\n",
    "        \n",
    "        #losowe cechy\n",
    "        neigh = KNeighborsClassifier(n_neighbors=k_neigh, algorithm='auto').fit(loc_x_random_train, loc_y_random_train)\n",
    "        y_random_pred = neigh.predict(loc_x_random_test)\n",
    "        random_score = accuracy_score(y_true = loc_y_random_test, y_pred = y_random_pred)\n",
    "        \n",
    "        print('best \\tm = %d, k = %d, score = %f' % (m, k_neigh, best_score))\n",
    "        print('random \\tm = %d, k = %d, score = %f' % (m, k_neigh, random_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowa tabelka na wyniki:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>(best | random)</th>\n",
    "        <th>k=1</th>\n",
    "        <th>k=3</th>\n",
    "        <th>k=5</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>m=N</th>\n",
    "        <td>0.93&nbsp;&nbsp;&nbsp;&nbsp;</td>\n",
    "        <td>0.94&nbsp;&nbsp;&nbsp;&nbsp;</td>\n",
    "        <td>0.95&nbsp;&nbsp;&nbsp;&nbsp;</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>m=2</th>\n",
    "        <td>0.94 | 0.74</td>\n",
    "        <td>0.93 | 0.82</td>\n",
    "        <td>0.94 | 0.83</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>m=5</th>\n",
    "        <td>0.95 | 0.75</td>\n",
    "        <td>0.93 | 0.76</td>\n",
    "        <td>0.93 | 0.75</td>\n",
    "    </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie\n",
    "---\n",
    "Analogicznie zbadać jakość klasyfikatorów dla danych <a href=\"https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set\"><b>Divorce Predictors data set Data Set</b></a>, w sprawozdaniu zamieścić wypełnioną tabelkę dla tych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macierz kowariancji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementami macierzy kowariancji są **współczynniki kowariancji** dla par zmiennych losowych opisanych przez parametry wiersza i kolumny macierzy. Macierz ta jest przeniesieniem pojęcia wariancji na przypadek **wielowymiarowy** (jest to macierz wartości oczekiwanych iloczynów wariancji analizowanych dwóch zmiennych).\n",
    "\n",
    "(Źródło: https://www.statystyka.az.pl/kowariancja-i-korelacja.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " “Covariance” indicates the direction of the linear relationship between variables. “Correlation” on the other hand measures both the **strength** and direction of the linear relationship between two variables. Correlation is a function of the covariance.\n",
    "\n",
    "(Źródło: https://towardsdatascience.com/let-us-understand-the-correlation-matrix-and-covariance-matrix-d42e6b643c22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation states how the features are related to each other or the target variable (= **modelowana zmienna**).\n",
    "\n",
    "*Intuicyjnie, jeśli wartość kowariancji jest większa (mniejsza) od 0, to wzrost wartości jednej z cech zwiększa (zmniejsza) wartość zmiennej modelowanej.*\n",
    "\n",
    "(Źródło: https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyznaczanie macierzy korelacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyznaczymy teraz macierz korelacji, aby później móc narysować **heatmapę**. Skorzystamy ze zbioru z danymi samochodów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/drazenz/heatmap/master/autos.clean.csv\")\n",
    "X = data.iloc[:,0:20]  #splitting data to independent columns\n",
    "y = data.iloc[:,-1]    #target column i.e price range\n",
    "# get correlations of each features in dataset\n",
    "corr_matrix = data.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I narysujemy tzw. **heatmap**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = corr_matrix.index  # e.g. horsepower\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "# plot heat map\n",
    "g=sns.heatmap(data[corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co można odczytać z heatmapy? Na przykład to, że im większy silnik samochodu, tym wyższa jego cena (engine-sine jest dodatnio skorelowany z price) albo że ilość obrotów na minutę praktycznie nie ma wpływu na cenę samochodu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacja PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA (ang. *Principal Component Analysis*), czyli **analiza głównych składowych** to podstawowa (i prawdopodobnie najczęściej stosowana) technika przetwarzania danych stosowana w celu zredukowania liczby wymiarów i zakresu (aby umożliwić *szybszą* analizę danych). Umożliwia ona podział wielowymiarowych zbiorów danych na zestaw niezależnych komponentów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorytm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA** identyfikuje kolejne osie zbioru danych o **najwyższej wariancji** (główne składowe). Algorytm transformacji PCA jest następujący: dla obliczonej macierz kowariancji wyznaczamy jej wartości własne i obliczamy wektory własne. Następnie są one normalizowane. Wektor własny o najwyższej wartości własnej jest *pierwszą główną składową*. Kolejne składowe są dobierane po malejących wartościach własnych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()  # cancer data in dictionary form\n",
    "cancer.keys()\n",
    "\n",
    "# dataframe is a two-dimensional, size-mutable, potentially heterogeneous tabular data\n",
    "df = pd.DataFrame(cancer['data'],columns=cancer['feature_names'])\n",
    "df.head()  # top values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy dużo cech do zobrazowania. Aby ułatwić sobie zadanie, skorzystamy z PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "scaled_data = scaler.transform(df) # scaling data\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)  # instantiate a PCA object\n",
    "pca.fit(scaled_data)  # find the principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca = pca.transform(scaled_data) # apply dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównajmy teraz wymiary danych przed i po zastosowaniu transformacji PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before PCA: {} vs after PCA: {}\".format(scaled_data.shape, x_pca.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liczba wymiarów *zmalała* do 2. Teraz możemy narysować wykres nowych cech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x_pca[:,0],x_pca[:,1],c=cancer['target'],cmap='rainbow')\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second Principal Component')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nowe cechy są **kombinacjami liniowymi** starych cech i są bardzo zróżnicowane. Zobaczymy to na heatmapie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = pd.DataFrame(pca.components_,columns=cancer['feature_names'])\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(map, cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po lewej stronie obok heatmapy widzimy wartości 0 i 1 które odpowiednio oznaczają nowo powstałe cechy. Na dole widać stare cechy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Źródła: https://datascienceplus.com/principal-component-analysis-pca-with-python/ oraz https://pdf.helion.pl/zaaucz/zaaucz.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz wyświetlimy histogram z 10-ma najlepszymi cechami:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights_0 = pca.components_[0]\n",
    "print(feature_weights_0)\n",
    "\n",
    "feat_importances_cancer = pd.Series(feature_weights_0, index=cancer['feature_names'])\n",
    "feat_importances_cancer.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights_1 = pca.components_[1]\n",
    "print(feature_weights_1)\n",
    "\n",
    "feat_importances_cancer = pd.Series(feature_weights_1, index=cancer['feature_names'])\n",
    "feat_importances_cancer.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widać, że cechy oraz wagi, z jakimi zostały one wybrane, są zupełnie inne niż w przypadku selekcji cech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Badanie jakości klasyfikatorów k-nn - porównanie z PCA\n",
    "---\n",
    "Zanim przejdziemy do porównywania jakości klasyfikatorów pokażemy na przykładzie, jak działa transformacja PCA do tego samego wymiaru danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytanie danych\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as n\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_cancer = pd.read_csv(\"data/wdbc.data\")\n",
    "# wyodrębnienie cech i klasyfikacji\n",
    "\n",
    "df_cancer_x = df_cancer.iloc[:,2:]\n",
    "df_cancer_y = df_cancer.iloc[:,1]\n",
    "data_cancer_x = df_cancer_x.to_numpy()\n",
    "data_cancer_y = df_cancer_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "loc_x_train, loc_x_test, loc_y_train, loc_y_test =  train_test_split(df_cancer_x,df_cancer_y, test_size=0.4, random_state=0 )\n",
    "\n",
    "scaler_cancer = preprocessing.Normalizer().fit(loc_x_train)\n",
    "loc_x_train_scaled = scaler_cancer.transform(loc_x_train)\n",
    "loc_x_test_scaled = scaler_cancer.transform(loc_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 30)#liczba cech w Winsconsin cancer\n",
    "\n",
    "pca.fit(loc_x_train_scaled)\n",
    "\n",
    "pca_x_train = pca.transform(loc_x_train_scaled)\n",
    "pca_x_test = pca.transform(loc_x_train_scaled)\n",
    "\n",
    "print(pca_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(loc_x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_x_train.shape, loc_x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wnioski z powyższego na podstawie wiedzy jak działa PCA powinno się umieścić w raporcie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porównywanie\n",
    "---\n",
    "Teraz przejdziemy do porównywania jakości klasyfikatorów k-nn dla pełnego zestawu cech, oraz wyselekcjowanego zestawu nowych cech. Nowe cechy powstaną poprzez przekształcenie PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler_cancer = preprocessing.Normalizer().fit(data_cancer_x)\n",
    "data_cancer_x_scaled = scaler_cancer.transform(data_cancer_x)\n",
    "\n",
    "bestfeatures_cancer = SelectKBest(score_func=chi2, k=10)\n",
    "fit_cancer = bestfeatures_cancer.fit(data_cancer_x_scaled, data_cancer_y)\n",
    "feat_importances_cancer = pd.Series(fit_cancer.scores_, index=df_cancer_x.columns)\n",
    "\n",
    "# zapisanie listy najlepszych cech\n",
    "\n",
    "best_cancer_features = feat_importances_cancer.nlargest(10).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "best_cancer_5 = best_cancer_features[:5]\n",
    "best_cancer_2 = best_cancer_features[:2]\n",
    "best_cancer = {\n",
    "    2: best_cancer_2,\n",
    "    5: best_cancer_5\n",
    "}\n",
    "\n",
    "# pomiar dla N (wszystkich) cech\n",
    "pca = PCA(30)\n",
    "for k_neigh in [1, 3, 5]:\n",
    "    loc_x_train, loc_x_test, loc_y_train, loc_y_test =  train_test_split(df_cancer_x,df_cancer_y, test_size=0.4,\n",
    "                                                                         random_state=0 )\n",
    "    \n",
    "    scaler_cancer = preprocessing.Normalizer().fit(loc_x_train)\n",
    "    loc_x_train_scaled = scaler_cancer.transform(loc_x_train)\n",
    "    loc_x_test_scaled = scaler_cancer.transform(loc_x_test)\n",
    "    \n",
    "    pca.fit(loc_x_train_scaled)\n",
    "    pca_x_train = pca.transform(loc_x_train_scaled)\n",
    "    pca_x_test = pca.transform(loc_x_test_scaled)\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=k_neigh, algorithm='auto').fit(loc_x_train, loc_y_train)\n",
    "    neigh_pca = KNeighborsClassifier(n_neighbors=k_neigh, algorithm='auto').fit(pca_x_train, loc_y_train)\n",
    "    y_pred = neigh.predict(loc_x_test)\n",
    "    y_pred_pca = neigh.predict(pca_x_test)\n",
    "    score = accuracy_score(y_true = loc_y_test, y_pred = y_pred)\n",
    "    pca_score = neigh_pca.score(pca_x_test, loc_y_test)\n",
    "    \n",
    "    print('all \\tm = N, k = %d, score = %f, pca_score = %f' % (k_neigh, score, pca_score))\n",
    "    \n",
    "    \n",
    "#pomiar m = 2, 5 najlepszych cech\n",
    "for m in [2, 5]:\n",
    "    loc_x_best_train, loc_x_best_test, loc_y_best_train, loc_y_best_test =  train_test_split(\n",
    "        df_cancer_x.loc[:,best_cancer[m]],df_cancer_y, test_size=0.4, random_state=0 )\n",
    "    \n",
    "    loc_x_train, loc_x_test, loc_y_train, loc_y_test =  train_test_split(df_cancer_x,df_cancer_y, test_size=0.4,\n",
    "                                                                         random_state=0 )\n",
    "    \n",
    "    pca = PCA(m)\n",
    "    scaler_cancer = preprocessing.Normalizer().fit(loc_x_train)\n",
    "    loc_x_best_train_scaled = scaler_cancer.transform(loc_x_train)\n",
    "    loc_x_best_test_scaled = scaler_cancer.transform(loc_x_test)\n",
    "    \n",
    "    pca.fit(loc_x_best_train_scaled)\n",
    "    pca_x_best_train = pca.transform(loc_x_best_train_scaled)\n",
    "    pca_x_best_test = pca.transform(loc_x_best_test_scaled)\n",
    "   \n",
    "    for k_neigh in [1, 3, 5]:\n",
    "        neigh = KNeighborsClassifier(n_neighbors=k_neigh, algorithm='auto').fit(loc_x_best_train, loc_y_best_train)\n",
    "        neigh_pca = KNeighborsClassifier(n_neighbors=k_neigh, algorithm='auto').fit(pca_x_best_train, loc_y_train)\n",
    "        y_best_pred = neigh.predict(loc_x_best_test)\n",
    "        y_best_pred_pca = neigh.predict(pca_x_best_test)\n",
    "        best_score = accuracy_score(y_true = loc_y_best_test, y_pred = y_best_pred)\n",
    "        pca_best_score = neigh_pca.score(pca_x_best_test, loc_y_best_test)\n",
    "        \n",
    "    \n",
    "        print('best \\tm = %d, k = %d, score = %f  pca_score = %f' % (m, k_neigh, best_score, pca_best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowa tabelka na wyniki (uzupełnioną zamieścić w sprawozdaniu):\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>(old | pca)</th>\n",
    "        <th>k=1</th>\n",
    "        <th>k=3</th>\n",
    "        <th>k=5</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>m=N</th>\n",
    "        <td>0.93 | 0.90</td>\n",
    "        <td>0.94 | 0.87</td>\n",
    "        <td>0.95 | 0.88</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>m=2</th>\n",
    "        <td>0.94 | 0.92</td>\n",
    "        <td>0.93 | 0.93</td>\n",
    "        <td>0.94 | 0.88</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>m=5</th>\n",
    "        <td>0.95 | 0.91</td>\n",
    "        <td>0.93 | 0.87</td>\n",
    "        <td>0.93 | 0.94</td>\n",
    "    </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Wizualizacja PCA\n",
    "## Wizualizacja 2D zbioru o N cechach\n",
    "---\n",
    "\n",
    "W tym punkcie zajmiemy się jedną z możliwości jaką dostarcza nam PCA - wizualizacją wielowymiarowych zbiorów danych. Kożystając z PCA możemy zmienić rozmiar zbioru cech do 2 lub 3 tym samym umożliwiając przedstawienie rozkładu danych w 2D lub 3D. Teraz zobaczymy jak prezentuje się w 2D zbiór **Breast Cancer Wisconsin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wczytanie danych\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df_cancer = pd.read_csv(\"data/wdbc.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyodrębnienie cech i klasyfikacji\n",
    "\n",
    "df_cancer_x = df_cancer.iloc[:,2:]\n",
    "df_cancer_y = df_cancer.iloc[:,1]\n",
    "data_cancer_x = df_cancer_x.to_numpy()\n",
    "data_cancer_y = df_cancer_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizacja danych\n",
    "\n",
    "scaler_cancer = preprocessing.Normalizer().fit(data_cancer_x)\n",
    "data_cancer_x_scaled = scaler_cancer.transform(data_cancer_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teraz przekształcamy nasze wielowymiarowe dane na 2-wymiarowe\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(data_cancer_x_scaled)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dodajemy klasyfikacje do komponentów\n",
    "\n",
    "finalDf = pd.concat([principalDf, pd.DataFrame(data_cancer_y, columns = ['diagnosis'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#i w koncu rysujemy wykres\n",
    "\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2D PCA', fontsize = 20)\n",
    "diagnosis = ['M', 'B']\n",
    "colors = ['r', 'g']\n",
    "for diagnose, color in zip(diagnosis,colors):\n",
    "    indicesToKeep = finalDf['diagnosis'] == diagnose\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(diagnosis)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać dane podzieliły się na dwa wyraźne podzbiory - zielony przyadki łagodne i czerwony przypadki złośliwe. Widać jednak że część punktów wyraźnie odstaje od skupiska, a niektóre mieszają się między sobą."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Szukanie outlierów\n",
    "---\n",
    "W tej części zajmiemy się poszukiwaniem danych odstających od reszty, tzw. outlierów oraz przykładów źle sklasyfikowanych, a następnie zaznaczymy je na powyższym wykresie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do znajdowania outlierów skorzystamy z metody <a href=\"https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/z-score/\"><b>Z-score</b></a>. Po krótce Z-score przeskalowuje i centralizuje dane, a następnie określa ich odległość od zera. Za outliery uznamy te dane, których wartość bezwzględna z Z-score będzie większa od 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "z = np.abs(stats.zscore(principalDf))\n",
    "data_cancer_outliers = principalDf[(z > 3).any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz wybierzemy przykłady które zostały źle zakwalifikowane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "loc_x_train, loc_x_test, loc_y_train, loc_y_test =  train_test_split(df_cancer_x,df_cancer_y, test_size=0.4,random_state=0 )\n",
    "\n",
    "scaler_cancer = preprocessing.Normalizer().fit(loc_x_train)\n",
    "loc_x_train_scaled = scaler_cancer.transform(loc_x_train)\n",
    "loc_x_test_scaled = scaler_cancer.transform(loc_x_test)\n",
    "\n",
    "pca = PCA(2)\n",
    "pca.fit(loc_x_train_scaled)\n",
    "pca_x_train = pca.transform(loc_x_train_scaled)\n",
    "pca_x_test = pca.transform(loc_x_test_scaled)\n",
    "\n",
    "neigh_pca = KNeighborsClassifier(n_neighbors=5, algorithm='auto').fit(pca_x_train, loc_y_train)\n",
    "y_pred_pca = neigh_pca.predict(pca_x_test)\n",
    "\n",
    "labels = loc_y_test.to_numpy()\n",
    "\n",
    "pca_x_test_df = pd.DataFrame(pca_x_test, columns = ['principal component 1', 'principal component 2'])\n",
    "pca_x_test_df = pca_x_test_df.set_index(loc_y_test.index)\n",
    "pca_x_test_df\n",
    "\n",
    "\n",
    "incorrects = pca_x_test_df[y_pred_pca != loc_y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz możemy stworzyć wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,15))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2D Visualisatin', fontsize = 20)\n",
    "diagnosis = ['M', 'B']\n",
    "colors = ['r', 'g']\n",
    "legend = ['M', 'B', 'Outliers', 'Incorrects']\n",
    "for diagnose, color in zip(diagnosis,colors):\n",
    "    indicesToKeep = finalDf['diagnosis'] == diagnose\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.scatter(data_cancer_outliers['principal component 1']\n",
    "              ,data_cancer_outliers['principal component 2']\n",
    "              , c = 'm'\n",
    "              , s = 50)\n",
    "ax.scatter(incorrects['principal component 1']\n",
    "              ,incorrects['principal component 2']\n",
    "              , c = 'k'\n",
    "              , s = 50)\n",
    "ax.legend(legend)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Zadanie\n",
    "---\n",
    "W zbiorach MNIST, NMIST, CIFAR-10 (wybrać tyle zbiorów, ile osób robi sprawozdanie). Do dalszych eksperymentów wybrać ilość przykładów nie większy niż M=2xN !!!(N- ilość cech):\n",
    "\n",
    "a.\t znaleźć NAJMNIEJ INFORMATYWNE cechy (piksele). Zobrazować je na rysunku, wielkością odpowiadającemu klasyfikowanym obrazkom.  \n",
    "b.\tDokonać klasyfikacji k-nn na pełnym zbiorze i zbiorze bez m najmniej informatywnych cech.  \n",
    "c.\tPrzetransformować zbiory przy pomocy PCA z N-D do N-D. Jak wyglądają (obrazki) wektory własne odpowiadające największym wartością własnym. Sprawdzić, czy poprawił się wynik klasyfikacji. Dokonać wizualizacji 2-D przy pomocy PCA.  \n",
    "d.\tUsunąć m najmniej informatywnych cech PCA. Jak wygląda wynik klasyfikacji.  \n",
    "e.\tWybrac m NAJLEPSZYCH cech PCA. Jak wygląda teraz wynik klasyfikacji.  \n",
    "f.\tWartość m w przypadku wyboru najgorszych cech ma być duże (dla N=784 jakieś m=500), w przypadku wyboru najlepszych małe (m=10-20)  \n",
    "g.\tDokonać klasyfikacji z PCA i bez PCA (na pełnym zbiorze cech i zadanym małym M), ale zwiększając ilość przykładów przy pomocy augmentacji (imgaug).  \n",
    "h.\tWnioski (co lepsze augmentacja czy inżynieria cech?)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
